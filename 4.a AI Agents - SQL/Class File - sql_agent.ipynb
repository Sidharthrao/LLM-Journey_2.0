{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd42c25",
   "metadata": {},
   "source": [
    "# SQL Agent: Natural Language to SQL Query Generator\n",
    "\n",
    "This notebook will teach you step-by-step how to build a robust SQL agent that converts natural language queries into PostgreSQL queries.\n",
    "\n",
    "## What We'll Build:\n",
    "1. **Database Connection Setup** - Connect to PostgreSQL database\n",
    "2. **Schema Discovery** - Automatically discover and understand database structure\n",
    "3. **Query Context Builder** - Create context for better query generation\n",
    "4. **AI-Powered SQL Generation** - Use LLM to convert natural language to SQL\n",
    "5. **Query Validation** - Validate and optimize generated queries\n",
    "6. **Interactive Interface** - Create a user-friendly interface\n",
    "\n",
    "## Database Information:\n",
    "- **Hostname**: hh-pgsql-public.ebi.ac.uk\n",
    "- **Port**: 5432\n",
    "- **Database**: pfmegrnargs\n",
    "- **User**: reader\n",
    "- **Password**: NWDMCE5xdipIjRrp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b7ac6c",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Dependencies\n",
    "\n",
    "First, let's install all the necessary packages for our SQL agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f48371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (2.9.10)\n",
      "Requirement already satisfied: pandas in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: sqlalchemy in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (2.0.41)\n",
      "Requirement already satisfied: openai in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (1.86.0)\n",
      "Requirement already satisfied: anthropic in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (0.54.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (1.1.0)\n",
      "Requirement already satisfied: langchain in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-anthropic in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (0.3.15)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from sqlalchemy) (4.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipywidgets) (9.3.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.14.0)\n",
      "Requirement already satisfied: wcwidth in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /Users/sidharthrao/Documents/Documents - Sidharth‚Äôs MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/c. Open AI/.venu_OpenAI/lib/python3.11/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install psycopg2-binary pandas sqlalchemy openai anthropic python-dotenv langchain langchain-openai langchain-anthropic\n",
    "\n",
    "# Alternative installations if needed\n",
    "# %pip install psycopg2  # for Windows\n",
    "%pip install ipywidgets  # For interactive widgets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8769c26",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cf8bcc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7de0a26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database libraries\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text, inspect\n",
    "\n",
    "# AI libraries\n",
    "import openai\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# Utility libraries\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956f10b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connected to PostgreSQL!\n",
      "üìä Database: dummy\n",
      "üîß Version: PostgreSQL 15.13 (Debian 15.13-1.pgdg120+1) on x86...\n"
     ]
    }
   ],
   "source": [
    "class PostgreSQLConnection:\n",
    "    \"\"\"\n",
    "    A robust PostgreSQL connection handler with error handling and connection management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, host, port, database, user, password):\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.database = database\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.connection = None\n",
    "        self.engine = None\n",
    "        \n",
    "    def connect(self):\n",
    "        \"\"\"Establish connection to PostgreSQL database\"\"\"\n",
    "        try:\n",
    "            # Create connection string\n",
    "            connection_string = f\"postgresql://{self.user}:{self.password}@{self.host}:{self.port}/{self.database}\"\n",
    "            \n",
    "            # Create SQLAlchemy engine\n",
    "            self.engine = create_engine(connection_string)\n",
    "            \n",
    "            # Test connection\n",
    "            with self.engine.connect() as conn:\n",
    "                result = conn.execute(text(\"SELECT version()\"))\n",
    "                version = result.fetchone()[0]\n",
    "                print(f\"‚úÖ Connected to PostgreSQL!\")\n",
    "                print(f\"üìä Database: {self.database}\")\n",
    "                print(f\"üîß Version: {version[:50]}...\")\n",
    "                \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Connection failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def execute_query(self, query, return_df=True):\n",
    "        \"\"\"Execute a SQL query and return results\"\"\"\n",
    "        try:\n",
    "            if return_df:\n",
    "                df = pd.read_sql_query(query, self.engine)\n",
    "                return df\n",
    "            else:\n",
    "                with self.engine.connect() as conn:\n",
    "                    result = conn.execute(text(query))\n",
    "                    return result.fetchall()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Query execution failed: {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def get_table_info(self):\n",
    "        \"\"\"Get information about all tables in the database\"\"\"\n",
    "        try:\n",
    "            inspector = inspect(self.engine)\n",
    "            tables_info = {}\n",
    "            \n",
    "            for table_name in inspector.get_table_names():\n",
    "                columns = inspector.get_columns(table_name)\n",
    "                tables_info[table_name] = {\n",
    "                    'columns': [col['name'] for col in columns],\n",
    "                    'column_details': columns\n",
    "                }\n",
    "                \n",
    "            return tables_info\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Failed to get table info: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "# Initialize database connection\n",
    "DB_CONFIG = {\n",
    "    'host': '54.251.218.166',\n",
    "    'port': 5432,\n",
    "    'database': 'dummy',\n",
    "    'user': 'rajesh',\n",
    "    'password': 'rajesh123'\n",
    "}\n",
    "\n",
    "# Create database connection\n",
    "db = PostgreSQLConnection(**DB_CONFIG)\n",
    "connection_success = db.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b99db6bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Penelope</td>\n",
       "      <td>Guiness</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Nick</td>\n",
       "      <td>Wahlberg</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Ed</td>\n",
       "      <td>Chase</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Davis</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Johnny</td>\n",
       "      <td>Lollobrigida</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>196</td>\n",
       "      <td>Bela</td>\n",
       "      <td>Walken</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197</td>\n",
       "      <td>Reese</td>\n",
       "      <td>West</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>198</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Keitel</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>199</td>\n",
       "      <td>Julia</td>\n",
       "      <td>Fawcett</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200</td>\n",
       "      <td>Thora</td>\n",
       "      <td>Temple</td>\n",
       "      <td>2013-05-26 14:47:57.620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actor_id first_name     last_name             last_update\n",
       "0           1   Penelope       Guiness 2013-05-26 14:47:57.620\n",
       "1           2       Nick      Wahlberg 2013-05-26 14:47:57.620\n",
       "2           3         Ed         Chase 2013-05-26 14:47:57.620\n",
       "3           4   Jennifer         Davis 2013-05-26 14:47:57.620\n",
       "4           5     Johnny  Lollobrigida 2013-05-26 14:47:57.620\n",
       "..        ...        ...           ...                     ...\n",
       "195       196       Bela        Walken 2013-05-26 14:47:57.620\n",
       "196       197      Reese          West 2013-05-26 14:47:57.620\n",
       "197       198       Mary        Keitel 2013-05-26 14:47:57.620\n",
       "198       199      Julia       Fawcett 2013-05-26 14:47:57.620\n",
       "199       200      Thora        Temple 2013-05-26 14:47:57.620\n",
       "\n",
       "[200 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.execute_query(\"select * from actor a;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cdfe285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abailable Tablees\n",
      "==================================================\n",
      "  1. actor (BASE TABLE)\n",
      "  2. actor_info (VIEW)\n",
      "  3. address (BASE TABLE)\n",
      "  4. category (BASE TABLE)\n",
      "  5. city (BASE TABLE)\n",
      "  6. country (BASE TABLE)\n",
      "  7. customer (BASE TABLE)\n",
      "  8. customer_list (VIEW)\n",
      "  9. film (BASE TABLE)\n",
      "  10. film_actor (BASE TABLE)\n",
      "  11. film_category (BASE TABLE)\n",
      "  12. film_list (VIEW)\n",
      "  13. inventory (BASE TABLE)\n",
      "  14. language (BASE TABLE)\n",
      "  15. nicer_but_slower_film_list (VIEW)\n",
      "  16. payment (BASE TABLE)\n",
      "  17. rental (BASE TABLE)\n",
      "  18. sales_by_film_category (VIEW)\n",
      "  19. sales_by_store (VIEW)\n",
      "  20. staff (BASE TABLE)\n",
      "  21. staff_list (VIEW)\n",
      "  22. store (BASE TABLE)\n",
      "\n",
      "üî¢ Total tables found: 22\n"
     ]
    }
   ],
   "source": [
    "if connection_success:\n",
    "     tables_query = \"\"\"\n",
    "    SELECT \n",
    "        table_name,\n",
    "        table_schema,\n",
    "        table_type\n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "    ORDER BY table_name;\n",
    "    \"\"\"\n",
    "     tables_df = db.execute_query(tables_query)\n",
    "     print(\"Abailable Tablees\")\n",
    "     print(\"=\"*50)\n",
    "     for idx, row in tables_df.iterrows():\n",
    "        print(f\"  {idx+1}. {row['table_name']} ({row['table_type']})\")\n",
    "     print(f\"\\nüî¢ Total tables found: {len(tables_df)}\")\n",
    "\n",
    "\n",
    "else:\n",
    "     print(\"trouble to connect with database\")\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2cbe847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Table: actor\n",
      "============================================================\n",
      "üìä Column Structure:\n",
      "  ‚Ä¢ actor_id: integer (NOT NULL) DEFAULT nextval('actor_actor_id_seq'::regclass)\n",
      "  ‚Ä¢ first_name: character varying (NOT NULL)\n",
      "  ‚Ä¢ last_name: character varying (NOT NULL)\n",
      "  ‚Ä¢ last_update: timestamp without time zone (NOT NULL) DEFAULT now()\n",
      "\n",
      "üìù Sample Data (first 5 rows):\n",
      "   actor_id first_name     last_name             last_update\n",
      "0         1   Penelope       Guiness 2013-05-26 14:47:57.620\n",
      "1         2       Nick      Wahlberg 2013-05-26 14:47:57.620\n",
      "2         3         Ed         Chase 2013-05-26 14:47:57.620\n",
      "3         4   Jennifer         Davis 2013-05-26 14:47:57.620\n",
      "4         5     Johnny  Lollobrigida 2013-05-26 14:47:57.620\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç Table: actor_info\n",
      "============================================================\n",
      "üìä Column Structure:\n",
      "  ‚Ä¢ actor_id: integer (NULL)\n",
      "  ‚Ä¢ first_name: character varying (NULL)\n",
      "  ‚Ä¢ last_name: character varying (NULL)\n",
      "  ‚Ä¢ film_info: text (NULL)\n",
      "\n",
      "üìù Sample Data (first 5 rows):\n",
      "   actor_id first_name     last_name                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               film_info\n",
      "0         1   Penelope       Guiness                                                                                                                                                              Animation: Anaconda Confessions, Children: Language Cowboy, Classics: Color Philadelphia, Westward Seabiscuit, Comedy: Vertigo Northwest, Documentary: Academy Dinosaur, Family: King Evolution, Splash Gump, Foreign: Mulholland Beast, Games: Bulworth Commandments, Human Graffiti, Horror: Elephant Trojan, Lady Stage, Rules Human, Music: Wizard Coldblooded, New: Angels Life, Oklahoma Jumanji, Sci-Fi: Cheaper Clyde, Sports: Gleaming Jawbreaker\n",
      "1         2       Nick      Wahlberg                                                                                      Action: Bull Shawshank, Animation: Fight Jawbreaker, Children: Jersey Sassy, Classics: Dracula Crystal, Gilbert Pelican, Comedy: Mallrats United, Rushmore Mermaid, Documentary: Adaptation Holes, Drama: Wardrobe Phantom, Family: Apache Divine, Chisum Behavior, Indian Love, Maguire Apache, Foreign: Baby Hall, Happiness United, Games: Roof Champion, Music: Lucky Flying, New: Destiny Saturday, Flash Wars, Jekyll Frogmen, Mask Peach, Sci-Fi: Chainsaw Uptown, Goodfellas Salute, Travel: Liaisons Sweet, Smile Earring\n",
      "2         3         Ed         Chase                                                                                                                                                                         Action: Caddyshack Jedi, Forrest Sons, Classics: Frost Head, Jeepers Wedding, Documentary: Army Flintstones, French Holiday, Halloween Nuts, Hunter Alter, Wedding Apollo, Young Language, Drama: Luck Opus, Necklace Outbreak, Spice Sorority, Foreign: Cowboy Doom, Whale Bikini, Music: Alone Trip, New: Eve Resurrection, Platoon Instinct, Sci-Fi: Weekend Personal, Sports: Artist Coldblooded, Image Princess, Travel: Boondock Ballroom\n",
      "3         4   Jennifer         Davis                                                                                                                                       Action: Barefoot Manchurian, Animation: Anaconda Confessions, Ghostbusters Elf, Comedy: Submarine Bed, Documentary: Bed Highball, National Story, Raiders Antitrust, Drama: Blade Polish, Greedy Roots, Family: Splash Gump, Horror: Treasure Command, Music: Hanover Galaxy, Reds Pocus, New: Angels Life, Jumanji Blade, Oklahoma Jumanji, Sci-Fi: Random Go, Silverado Goldfinger, Unforgiven Zoolander, Sports: Instinct Airport, Poseidon Forever, Travel: Boondock Ballroom\n",
      "4         5     Johnny  Lollobrigida  Action: Amadeus Holy, Grail Frankenstein, Rings Heartbreakers, Animation: Sunrise League, Children: Hall Cassidy, Comedy: Daddy Pittsburgh, Documentary: Bonnie Holocaust, Metal Armageddon, Pacific Amistad, Pocus Pulp, Drama: Chitty Lock, Coneheads Smoochy, Games: Fire Wolves, Horror: Commandments Express, Love Suicides, Patton Interview, Music: Banger Pinocchio, Heavenly Gun, New: Frontier Cabin, Ridgemont Submarine, Sci-Fi: Daisy Menagerie, Goodfellas Salute, Soldiers Evolution, Sports: Groove Fiction, Kramer Chocolate, Star Operation, Travel: Enough Raging, Escape Metropolis, Smile Earring\n",
      "\n",
      "============================================================\n",
      "\n",
      "üîç Table: address\n",
      "============================================================\n",
      "üìä Column Structure:\n",
      "  ‚Ä¢ address_id: integer (NOT NULL) DEFAULT nextval('address_address_id_seq'::regclass)\n",
      "  ‚Ä¢ address: character varying (NOT NULL)\n",
      "  ‚Ä¢ address2: character varying (NULL)\n",
      "  ‚Ä¢ district: character varying (NOT NULL)\n",
      "  ‚Ä¢ city_id: smallint (NOT NULL)\n",
      "  ‚Ä¢ postal_code: character varying (NULL)\n",
      "  ‚Ä¢ phone: character varying (NOT NULL)\n",
      "  ‚Ä¢ last_update: timestamp without time zone (NOT NULL) DEFAULT now()\n",
      "\n",
      "üìù Sample Data (first 5 rows):\n",
      "   address_id               address address2  district  city_id postal_code        phone         last_update\n",
      "0           1     47 MySakila Drive     None   Alberta      300                          2006-02-15 09:45:30\n",
      "1           2    28 MySQL Boulevard     None       QLD      576                          2006-02-15 09:45:30\n",
      "2           3     23 Workhaven Lane     None   Alberta      300              14033335568 2006-02-15 09:45:30\n",
      "3           4  1411 Lillydale Drive     None       QLD      576               6172235589 2006-02-15 09:45:30\n",
      "4           5        1913 Hanoi Way           Nagasaki      463       35200  28303384290 2006-02-15 09:45:30\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def explore_table_structure(table_name, limit=5):\n",
    "    columns_query = f\"\"\"\n",
    "    SELECT \n",
    "        column_name,\n",
    "        data_type,\n",
    "        is_nullable,\n",
    "        column_default\n",
    "    FROM information_schema.columns \n",
    "    WHERE table_name = '{table_name}'\n",
    "    ORDER BY ordinal_position;\n",
    "    \"\"\"\n",
    "    columns_df = db.execute_query(columns_query)\n",
    "    print(f\"üîç Table: {table_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"üìä Column Structure:\")\n",
    "    for idx, row in columns_df.iterrows():\n",
    "        nullable = \"NULL\" if row['is_nullable'] == 'YES' else \"NOT NULL\"\n",
    "        default = f\" DEFAULT {row['column_default']}\" if row['column_default'] else \"\"\n",
    "        print(f\"  ‚Ä¢ {row['column_name']}: {row['data_type']} ({nullable}){default}\")\n",
    "    # Get sample data\n",
    "    sample_query = f\"SELECT * FROM {table_name} LIMIT {limit};\"\n",
    "    sample_df = db.execute_query(sample_query)\n",
    "    \n",
    "    print(f\"\\nüìù Sample Data (first {limit} rows):\")\n",
    "    if sample_df is not None and not sample_df.empty:\n",
    "        print(sample_df.to_string())\n",
    "    else:\n",
    "        print(\"  No data found or query failed\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    return columns_df, sample_df\n",
    "\n",
    "\n",
    "if connection_success and not tables_df.empty:\n",
    "    # Take first few tables to explore\n",
    "    tables_to_explore = tables_df['table_name'].head(3).tolist()\n",
    "    \n",
    "    for table in tables_to_explore:\n",
    "        try:\n",
    "            explore_table_structure(table)\n",
    "            print()\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error exploring {table}: {str(e)}\")\n",
    "            print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450e3f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Schema context builder initialized!\n",
      "üìä Cached schema for 22 tables\n"
     ]
    }
   ],
   "source": [
    "class SchemaContextBuilder:\n",
    "    \"\"\"\n",
    "    Builds context about database schema for AI models to generate accurate SQL queries\n",
    "    \"\"\"\n",
    "    def __init__(self, db_connection):\n",
    "        self.db = db_connection\n",
    "        self.schema_cache = {}\n",
    "        self.build_full_schema_context()\n",
    "\n",
    "    def build_full_schema_context(self):\n",
    "        \"\"\"Build complete schema context for all tables\"\"\"\n",
    "        \n",
    "        # Get all tables\n",
    "        tables_query = \"\"\"\n",
    "        SELECT table_name, table_schema \n",
    "        FROM information_schema.tables \n",
    "        WHERE table_schema = 'public'\n",
    "        ORDER BY table_name;\n",
    "        \"\"\"\n",
    "        tables_df = self.db.execute_query(tables_query)\n",
    "        if tables_df is None:\n",
    "            return\n",
    "        for _, row in tables_df.iterrows():\n",
    "            table_name = row['table_name']\n",
    "            self.schema_cache[table_name] = self.get_table_schema(table_name)\n",
    "\n",
    "    def get_table_schema(self, table_name):\n",
    "        \"\"\"Get detailed schema for a specific table\"\"\"\n",
    "\n",
    "        columns_query = f\"\"\"\n",
    "        SELECT \n",
    "            column_name,\n",
    "            data_type,\n",
    "            is_nullable,\n",
    "            column_default,\n",
    "            character_maximum_length\n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name = '{table_name}'\n",
    "        ORDER BY ordinal_position;\n",
    "        \"\"\"\n",
    "        columns_df = self.db.execute_query(columns_query)\n",
    "\n",
    "        if columns_df is None:\n",
    "            return None\n",
    "        \n",
    "        # Get foreign key relationships\n",
    "        fk_query = f\"\"\"\n",
    "        SELECT\n",
    "            kcu.column_name,\n",
    "            ccu.table_name AS foreign_table_name,\n",
    "            ccu.column_name AS foreign_column_name\n",
    "        FROM information_schema.table_constraints AS tc\n",
    "        JOIN information_schema.key_column_usage AS kcu\n",
    "            ON tc.constraint_name = kcu.constraint_name\n",
    "        JOIN information_schema.constraint_column_usage AS ccu\n",
    "            ON ccu.constraint_name = tc.constraint_name\n",
    "        WHERE tc.constraint_type = 'FOREIGN KEY'\n",
    "            AND tc.table_name = '{table_name}';\n",
    "        \"\"\"\n",
    "\n",
    "        fk_df = self.db.execute_query(fk_query)\n",
    "\n",
    "        # Build schema info\n",
    "        schema_info = {\n",
    "            'table_name': table_name,\n",
    "            'columns': [],\n",
    "            'foreign_keys': []\n",
    "        }\n",
    "\n",
    "        for _, col in columns_df.iterrows():\n",
    "            col_info = {\n",
    "                'name': col['column_name'],\n",
    "                'type': col['data_type'],\n",
    "                'nullable': col['is_nullable'] == 'YES',\n",
    "                'default': col['column_default'],\n",
    "                'max_length': col['character_maximum_length']\n",
    "            }\n",
    "            schema_info['columns'].append(col_info)\n",
    "\n",
    "        if fk_df is not None and not fk_df.empty:\n",
    "            for _, fk in fk_df.iterrows():\n",
    "                fk_info = {\n",
    "                    'column': fk['column_name'],\n",
    "                    'references_table': fk['foreign_table_name'],\n",
    "                    'references_column': fk['foreign_column_name']\n",
    "                }\n",
    "                schema_info['foreign_keys'].append(fk_info)\n",
    "        \n",
    "        return schema_info\n",
    "    \n",
    "\n",
    "    def get_relevant_tables(self, query_text):\n",
    "        \"\"\"Identify tables that might be relevant to the query\"\"\"\n",
    "        query_lower = query_text.lower()\n",
    "        relevant_tables = []\n",
    "        \n",
    "        for table_name in self.schema_cache.keys():\n",
    "            # Check if table name appears in query\n",
    "            if table_name.lower() in query_lower:\n",
    "                relevant_tables.append(table_name)\n",
    "                continue\n",
    "                \n",
    "            # Check if any column names appear in query\n",
    "            schema = self.schema_cache[table_name]\n",
    "            if schema:\n",
    "                for col in schema['columns']:\n",
    "                    if col['name'].lower() in query_lower:\n",
    "                        relevant_tables.append(table_name)\n",
    "                        break\n",
    "        \n",
    "        # If no specific tables found, return first few tables\n",
    "        if not relevant_tables:\n",
    "            relevant_tables = list(self.schema_cache.keys())[:5]\n",
    "            \n",
    "        return relevant_tables\n",
    "    \n",
    "    def build_context_for_query(self, query_text):\n",
    "        \"\"\"Build focused context for a specific query\"\"\"\n",
    "        relevant_tables = self.get_relevant_tables(query_text)\n",
    "        \n",
    "        context = f\"\"\"\n",
    "DATABASE SCHEMA INFORMATION:\n",
    "Database: {self.db.database}\n",
    "Relevant Tables for Query: \"{query_text}\"\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "        for table_name in relevant_tables:\n",
    "            schema = self.schema_cache.get(table_name)\n",
    "            if not schema:\n",
    "                continue\n",
    "                \n",
    "            context += f\"TABLE: {table_name}\\n\"\n",
    "            context += \"Columns:\\n\"\n",
    "            \n",
    "            for col in schema['columns']:\n",
    "                nullable = \"NULL\" if col['nullable'] else \"NOT NULL\"\n",
    "                context += f\"  - {col['name']}: {col['type']} ({nullable})\\n\"\n",
    "            \n",
    "            if schema['foreign_keys']:\n",
    "                context += \"Foreign Keys:\\n\"\n",
    "                for fk in schema['foreign_keys']:\n",
    "                    context += f\"  - {fk['column']} -> {fk['references_table']}.{fk['references_column']}\\n\"\n",
    "            \n",
    "            context += \"\\n\"\n",
    "        \n",
    "        return context\n",
    "    \n",
    "\n",
    "# Initialize schema builder\n",
    "if connection_success:\n",
    "    schema_builder = SchemaContextBuilder(db)\n",
    "    print(\"‚úÖ Schema context builder initialized!\")\n",
    "    print(f\"üìä Cached schema for {len(schema_builder.schema_cache)} tables\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot initialize schema builder - no database connection\")\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# sc = SchemaContextBuilder(db)\n",
    "# sc.get_table_schema(\"film\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4858675c",
   "metadata": {},
   "source": [
    "### Agent Building Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea8b4d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI GPT-4o-mini available\n",
      "\n",
      "üìä Available models: ['openai']\n"
     ]
    }
   ],
   "source": [
    "# AI Configuration\n",
    "# You'll need to set your API keys here\n",
    "# Option 1: Set as environment variables\n",
    "# export OPENAI_API_KEY=\"your-openai-key\"\n",
    "# export ANTHROPIC_API_KEY=\"your-anthropic-key\"\n",
    "\n",
    "# Option 2: Set directly in code (less secure)\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your-openai-key\"\n",
    "# os.environ[\"ANTHROPIC_API_KEY\"] = \"your-anthropic-key\"\n",
    "\n",
    "def get_available_models():\n",
    "    \"\"\"Check which AI models are available based on API keys\"\"\"\n",
    "    models = {}\n",
    "    \n",
    "    # Check OpenAI\n",
    "    if os.getenv(\"OPENAI_API_KEY\"):\n",
    "        try:\n",
    "            models[\"openai\"] = ChatOpenAI(\n",
    "                model=\"gpt-4o-mini\",  # Cost-effective but powerful\n",
    "                temperature=0.1,      # Low temperature for consistent SQL generation\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            print(\"‚úÖ OpenAI GPT-4o-mini available\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå OpenAI setup failed: {str(e)}\")\n",
    "    \n",
    "    # Check Anthropic\n",
    "    if os.getenv(\"ANTHROPIC_API_KEY\"):\n",
    "        try:\n",
    "            models[\"anthropic\"] = ChatAnthropic(\n",
    "                model=\"claude-3-haiku-20240307\",  # Fast and cost-effective\n",
    "                temperature=0.1,\n",
    "                max_tokens=1000\n",
    "            )\n",
    "            print(\"‚úÖ Anthropic Claude available\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Anthropic setup failed: {str(e)}\")\n",
    "    \n",
    "    if not models:\n",
    "        print(\"‚ö†Ô∏è  No AI models available. Please set your API keys.\")\n",
    "        print(\"   You can use OpenAI, Anthropic, or other compatible models.\")\n",
    "        print(\"   For this tutorial, we'll create a mock model for demonstration.\")\n",
    "        \n",
    "        # Create a mock model for demonstration\n",
    "        class MockModel:\n",
    "            def invoke(self, messages):\n",
    "                # Simple pattern matching for demo\n",
    "                user_msg = messages[-1].content.lower()\n",
    "                \n",
    "                if \"count\" in user_msg and \"table\" in user_msg:\n",
    "                    return type('Response', (), {'content': 'SELECT COUNT(*) FROM your_table_name;'})()\n",
    "                elif \"select\" in user_msg or \"show\" in user_msg:\n",
    "                    return type('Response', (), {'content': 'SELECT * FROM your_table_name LIMIT 10;'})()\n",
    "                else:\n",
    "                    return type('Response', (), {'content': 'SELECT * FROM your_table_name WHERE condition = value;'})()\n",
    "        \n",
    "        models[\"mock\"] = MockModel()\n",
    "        print(\"‚úÖ Mock model created for demonstration\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Initialize available models\n",
    "available_models = get_available_models()\n",
    "print(f\"\\nüìä Available models: {list(available_models.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6f4e3",
   "metadata": {},
   "source": [
    "# SQL AGENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c7b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLAgent:\n",
    "    \"\"\"\n",
    "    A robust SQL Agent that converts natural language queries to SQL using AI\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_connection, schema_builder, ai_model, model_name=\"default\"):\n",
    "        self.db = db_connection\n",
    "        self.schema_builder = schema_builder\n",
    "        self.ai_model = ai_model\n",
    "        self.model_name = model_name\n",
    "        self.query_history = []\n",
    "\n",
    "    def create_system_prompt(self):\n",
    "        \"\"\"Create a comprehensive system prompt for SQL generation\"\"\"\n",
    "        \n",
    "        system_prompt = \"\"\"You are an expert PostgreSQL database analyst. Your job is to convert natural language questions into accurate, efficient SQL queries.\n",
    "\n",
    "IMPORTANT GUIDELINES:\n",
    "1. Always use proper PostgreSQL syntax\n",
    "2. Use appropriate table and column names from the provided schema\n",
    "3. Include proper JOINs when querying multiple tables\n",
    "4. Use LIMIT clauses for exploratory queries to avoid large result sets\n",
    "5. Handle NULL values appropriately\n",
    "6. Use proper date/time functions for temporal queries\n",
    "7. Return ONLY the SQL query, no explanations or markdown formatting\n",
    "8. Make queries efficient and avoid unnecessary complexity\n",
    "\n",
    "QUERY STRUCTURE:\n",
    "- Use SELECT statements for data retrieval\n",
    "- Use appropriate WHERE clauses for filtering\n",
    "- Use GROUP BY and aggregation functions when needed\n",
    "- Use ORDER BY for sorting results\n",
    "- Use proper JOIN syntax for multi-table queries\n",
    "\n",
    "COMMON PATTERNS:\n",
    "- For counts: SELECT COUNT(*) FROM table_name WHERE condition\n",
    "- For lists: SELECT column_name FROM table_name WHERE condition LIMIT 10\n",
    "- For aggregations: SELECT column_name, AGG_FUNCTION(column) FROM table_name GROUP BY column_name\n",
    "- For date ranges: WHERE date_column BETWEEN 'start_date' AND 'end_date'\n",
    "\n",
    "Remember: Return only valid PostgreSQL SQL queries that can be executed directly.\"\"\"\n",
    "\n",
    "        return system_prompt\n",
    "    \n",
    "    def generate_sql_query(self, natural_language_query):\n",
    "            \n",
    "            \"\"\"Convert natural language to SQL query\"\"\"\n",
    "            \n",
    "            try:\n",
    "                # Build context for the query\n",
    "                schema_context = self.schema_builder.build_context_for_query(natural_language_query)\n",
    "                \n",
    "                # Create messages for the AI model\n",
    "                system_prompt = self.create_system_prompt()\n",
    "                \n",
    "                user_prompt = f\"\"\"\n",
    "    {schema_context}\n",
    "\n",
    "    Convert this natural language question to a PostgreSQL query:\n",
    "    \"{natural_language_query}\"\n",
    "\n",
    "    Return only the SQL query, nothing else.\n",
    "    \"\"\"\n",
    "                \n",
    "                # Prepare messages\n",
    "                messages = [\n",
    "                    SystemMessage(content=system_prompt),\n",
    "                    HumanMessage(content=user_prompt)\n",
    "                ]\n",
    "                \n",
    "                # Generate SQL using AI model\n",
    "                response = self.ai_model.invoke(messages)\n",
    "                sql_query = response.content.strip()\n",
    "                \n",
    "                # Clean up the response (remove markdown formatting if present)\n",
    "                sql_query = self.clean_sql_response(sql_query)\n",
    "                \n",
    "                # Store in history\n",
    "                self.query_history.append({\n",
    "                    'natural_language': natural_language_query,\n",
    "                    'sql_query': sql_query,\n",
    "                    'timestamp': datetime.now(),\n",
    "                    'model': self.model_name\n",
    "                })\n",
    "                \n",
    "                return sql_query\n",
    "            except Exception as e:\n",
    "                error_msg = f\"Error generating SQL: {str(e)}\"\n",
    "                print(f\"‚ùå {error_msg}\")\n",
    "                return None\n",
    "    \n",
    "    def clean_sql_response(self, sql_response):\n",
    "        \"\"\"Clean up SQL response from AI model\"\"\"\n",
    "        \n",
    "        # Remove markdown code blocks\n",
    "        sql_response = re.sub(r'```sql\\n', '', sql_response)\n",
    "        sql_response = re.sub(r'```\\n', '', sql_response)\n",
    "        sql_response = re.sub(r'```', '', sql_response)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        sql_response = sql_response.strip()\n",
    "        \n",
    "        # Ensure it ends with semicolon\n",
    "        if not sql_response.endswith(';'):\n",
    "            sql_response += ';'\n",
    "            \n",
    "        return sql_response\n",
    "    \n",
    "\n",
    "    def validate_sql_query(self, sql_query):\n",
    "\n",
    "        \"\"\"Validate SQL query syntax without executing it\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Use EXPLAIN to validate without executing\n",
    "            explain_query = f\"EXPLAIN {sql_query}\"\n",
    "            with self.db.engine.connect() as conn:\n",
    "                conn.execute(text(explain_query))\n",
    "            return True, \"Query is valid\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            return False, f\"Query validation failed: {str(e)}\"\n",
    "        \n",
    "    def execute_query_safely(self, sql_query, max_rows=100):\n",
    "        \"\"\"Execute SQL query with safety limits\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Validate first\n",
    "            is_valid, validation_msg = self.validate_sql_query(sql_query)\n",
    "            \n",
    "            if not is_valid:\n",
    "                return None, validation_msg\n",
    "            \n",
    "            # Add LIMIT if not present for SELECT queries\n",
    "            if sql_query.upper().strip().startswith('SELECT') and 'LIMIT' not in sql_query.upper():\n",
    "                sql_query = sql_query.rstrip(';') + f' LIMIT {max_rows};'\n",
    "            \n",
    "            # Execute query\n",
    "            result_df = self.db.execute_query(sql_query)\n",
    "            \n",
    "            if result_df is not None:\n",
    "                return result_df, f\"Query executed successfully. Returned {len(result_df)} rows.\"\n",
    "            else:\n",
    "                return None, \"Query execution failed\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return None, f\"Execution error: {str(e)}\"\n",
    "    \n",
    "\n",
    "\n",
    "    def query(self, natural_language_query, execute=True, max_rows=100):\n",
    "        \"\"\"\n",
    "        Main method to convert natural language to SQL and optionally execute it\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"ü§î Question: {natural_language_query}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Generate SQL\n",
    "        sql_query = self.generate_sql_query(natural_language_query)\n",
    "        \n",
    "        if sql_query is None:\n",
    "            return None, None\n",
    "        \n",
    "        print(f\"üîß Generated SQL:\")\n",
    "        print(sql_query)\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        if execute:\n",
    "            # Execute the query\n",
    "            result_df, message = self.execute_query_safely(sql_query, max_rows)\n",
    "            print(f\"üìä {message}\")\n",
    "            \n",
    "            if result_df is not None and not result_df.empty:\n",
    "                print(\"\\nüìã Results:\")\n",
    "                print(result_df.to_string())\n",
    "            \n",
    "            return sql_query, result_df\n",
    "        else:\n",
    "            return sql_query, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4fdecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Question: How much money did Matthew and Kirsten make for all the films they acted in?\n",
      "================================================================================\n",
      "üîß Generated SQL:\n",
      "SELECT SUM(f.rental_rate) AS total_earnings \n",
      "FROM film f \n",
      "JOIN staff_list s ON f.film_id = s.id \n",
      "WHERE s.name IN ('Matthew', 'Kirsten');\n",
      "----------------------------------------\n",
      "üìä Query executed successfully. Returned 1 rows.\n",
      "\n",
      "üìã Results:\n",
      "  total_earnings\n",
      "0           None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"SELECT SUM(f.rental_rate) AS total_earnings \\nFROM film f \\nJOIN staff_list s ON f.film_id = s.id \\nWHERE s.name IN ('Matthew', 'Kirsten');\",\n",
       "   total_earnings\n",
       " 0           None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = list(available_models.keys())[0]\n",
    "selected_model = available_models[model_name]\n",
    "\n",
    "sql_agent = SQLAgent(\n",
    "        db_connection=db,\n",
    "        schema_builder=schema_builder,\n",
    "        ai_model=selected_model,\n",
    "        model_name=model_name\n",
    "    )\n",
    "\n",
    "sql_agent.query(\"How much money did Matthew and Kirsten make for all the films they acted in?\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b236baaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venu_OpenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
