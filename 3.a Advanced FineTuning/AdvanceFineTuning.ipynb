{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bf838cc",
   "metadata": {},
   "source": [
    "### Advance FineTuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8dfa1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U transformers datasets accelerate peft trl bitsandbytes wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f873f108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/n. Advanced FineTuning/.venv_AdvFT/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490a7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Login to Hugging Face\n",
    "# Option 1: Use token from environment variable\n",
    "hf_token = os.getenv(\"HF_TOKEN\") or os.getenv(\"HUGGINGFACE_TOKEN\")\n",
    "if hf_token:\n",
    "    login(token=hf_token)\n",
    "else:\n",
    "    # Option 2: Prompt for token (for interactive use)\n",
    "    # login()  # This will prompt for token\n",
    "    print(\"Please set HF_TOKEN or HUGGINGFACE_TOKEN environment variable, or use login() to enter token interactively\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb14c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c702eafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "Tokenizer loaded successfully!\n",
      "Loading model...\n",
      "Model loaded successfully!\n",
      "Model device: mps:0\n",
      "Model dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "print(\"Loading tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "print(\"Tokenizer loaded successfully!\")\n",
    "\n",
    "print(\"Loading model...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", device_map=\"mps\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test if model is working\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Model dtype: {next(model.parameters()).dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09641cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user',\n",
       "    'content': 'How can I reset my password?\\t'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'To reset your password, follow these steps:\\n\\n1. Login to your PayPal account.\\n2. Go to your account settings.\\n3. Scroll down to the \"Password\" section, and click on \"Change Password.\"\\n4. Enter your current password in the \"Current Password\" field.\\n5. Enter your new password in the \"New Password\" field.\\n6. Enter your confirmation password in the \"Confirm Password\" field.\\n7. Click on the \"Change Password\" button.\\n8. PayPal will generate a new password for you.\\n\\nNote: If you do not remember your current password, you can also use the \"Forgot Password\" feature to generate a new one.\\n\\nOnce you have reset your password, you will be prompted to verify your account by logging in with your new password.'}]}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"How can I reset my password?\t\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b8f65c",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79e13008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/n. Advanced FineTuning/.venv_AdvFT/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5fe9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./llama-chatbot-finetuned\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    #fp16=True,\n",
    "    # evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2197c666",
   "metadata": {},
   "source": [
    "#### Supervised Fine-Tuning Trainer Setup use the SFTTrainer or Trainer class for supervised fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "865cd1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I reset my password?</td>\n",
       "      <td>To reset your password, go to the login page a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are your store hours?</td>\n",
       "      <td>Our store is open from 9 AM to 9 PM Monday thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you help me track my order?</td>\n",
       "      <td>Yes, provide me with your order number and I'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the refund policy?</td>\n",
       "      <td>Our refund policy allows returns within 30 day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I contact customer service?</td>\n",
       "      <td>mailto:support@store.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          instruction  \\\n",
       "0        How can I reset my password?   \n",
       "1          What are your store hours?   \n",
       "2     Can you help me track my order?   \n",
       "3          What is the refund policy?   \n",
       "4  How do I contact customer service?   \n",
       "\n",
       "                                            response  \n",
       "0  To reset your password, go to the login page a...  \n",
       "1  Our store is open from 9 AM to 9 PM Monday thr...  \n",
       "2  Yes, provide me with your order number and I'l...  \n",
       "3  Our refund policy allows returns within 30 day...  \n",
       "4                           mailto:support@store.com  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/n. Advanced FineTuning/instruction-response.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "513212ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0d0e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74674cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Map: 100%|██████████| 10/10 [00:00<00:00, 2722.69 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def concat_instruction_response(example):\n",
    "    return {\"text\": f\"Instruction: {example['instruction']}\\nResponse: {example['response']}\"}\n",
    "\n",
    "dataset = dataset.map(concat_instruction_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13cdaf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding EOS to train dataset: 100%|██████████| 10/10 [00:00<00:00, 5435.15 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 10/10 [00:00<00:00, 2948.13 examples/s]\n",
      "Truncating train dataset: 100%|██████████| 10/10 [00:00<00:00, 5467.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    args=training_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11a1f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab3e416",
   "metadata": {},
   "source": [
    "everyweek \n",
    "2 research paper\n",
    "1 GenAI - FineTuning -> ash Rajesh for weekly target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01ee68a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sidharthrao/Documents/Documents - Sidharth’s MacBook Pro/GitHub/Project-Dash/2. GenAI and AgenticAI/ii. Class Sessions/n. Advanced FineTuning/.venv_AdvFT/lib/python3.11/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5/5 00:01, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5, training_loss=1.8463024139404296, metrics={'train_runtime': 1.6928, 'train_samples_per_second': 5.907, 'train_steps_per_second': 2.954, 'total_flos': 2348828762112.0, 'train_loss': 1.8463024139404296})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39337fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9d72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abd5562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d6dfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e237b88e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_AdvFT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
